{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import fastparquet\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with test data\n",
    "input_data = pd.read_parquet('../test_files/merged_cow_with_feed_daily_20230530_1557.parquet')\n",
    "# Remove animals missing diet information\n",
    "input_data_dropna = input_data.dropna(subset=['sampleId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Data: Step 1\n",
    "# Move diet information to the database and replace with unique Diet_ID\n",
    "\n",
    "def check_diets(df):\n",
    "    # Create dataframe with each unique diet\n",
    "    unique_diets = df[['sampleId', 'reportDate']].drop_duplicates()\n",
    "    unique_diet_list = unique_diets.index.values.tolist()\n",
    "\n",
    "    # Index numbers in list are off because I deleted the top of the dataframe with missing feed data\n",
    "    # If I had not then 'diet_data' could be used here instead of 'input_data'\n",
    "    current_diets = input_data.iloc[unique_diet_list]\n",
    "\n",
    "    # Removing all non diet data \n",
    "    columns_to_remove = ['lactation_number', 'days_in_milk', 'MY', 'weight', 'BW_smooth', 'BW_gain', 'asfed_intake', 'DMI', 'bcs_value', 'Birth Date', 'Test Day Date',\n",
    "                        'Lact Start Date', 'Fat %', 'Protein %', 'SCC', 'Pregnancy Indicator', 'Days to Last Breeding', 'days_preg', 'conception_date', 'age_m', 'cow_id', 'date', 'DIM_bins_w']\n",
    "    current_diets = current_diets.drop(columns=columns_to_remove)\n",
    "\n",
    "    # Add Diet_ID\n",
    "    current_diets = current_diets.assign(\n",
    "        Diet_ID = lambda df: df['sampleId'] + '_' + df['reportDate'].dt.strftime('%Y-%m-%d')\n",
    "        )\n",
    "\n",
    "    return current_diets\n",
    "\n",
    "\n",
    "def save_to_database(df, table_name, index):\n",
    "    # Save current diets to database\n",
    "    conn = sqlite3.connect('../diet_database.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    df.set_index(index, inplace=True)\n",
    "    df.to_sql(table_name, conn, if_exists='replace')\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "current_diets = check_diets(input_data_dropna)\n",
    "# print(current_diets.iloc[:, :6].head(1))\n",
    "save_to_database(current_diets,'current_diets', 'Diet_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cow_id  An_Parity_rl  An_LactDay  Trg_MilkProd    An_BW  BW_gain\n",
      "0    4921             1       140.0         27.81  668.875    1.550\n",
      "1    4823             2        72.0         31.97  729.982    0.773\n"
     ]
    }
   ],
   "source": [
    "# Cleaning Data: Step 2 \n",
    "# Rename columns, add default values, remove unecessary columns, add Diet_ID\n",
    "\n",
    "def clean_input_data(df):\n",
    "    # Rename existing columns\n",
    "    df = df.rename(columns={\n",
    "        'lactation_number': 'An_Parity_rl',\n",
    "        'days_in_milk': 'An_LactDay',\n",
    "        'MY': 'Trg_MilkProd',\n",
    "        'BW_smooth': 'An_BW',\n",
    "        'DMI': 'Dt_DMIn',\n",
    "        'Fat %': 'Trg_MilkFatp',\n",
    "        'Protein %': 'Trg_MilkTPp',\n",
    "        'days_preg': 'An_GestDay'\n",
    "        })\n",
    "    \n",
    "    # Add default values\n",
    "    df['An_BW_mature'] = 700\n",
    "    df['Trg_FrmGain'] = 0\n",
    "    df['An_GestLength'] = 280\n",
    "    df['Fet_BWbrth'] = 44.1\n",
    "    df['Trg_MilkLacp'] = 4.85\n",
    "    df['Trg_RsrvGain'] = 0\n",
    "    df['An_AgeDay'] = df['age_m'] * 30.436875\n",
    "    \n",
    "    # Remove diet information\n",
    "    diet_columns = ['location', 'Acid Detergent Fibre (%)', 'Ash (%)', 'Calcium (%)', 'Copper (ug/g)', 'Crude Fat (%)', 'Crude Protein (%)', 'Dry Matter (%)', 'Iron (ug/g)', 'Magnesium (%)', 'Manganese (ug/g)', 'Moisture (%)', 'NE Gain (MCal/Kg)', 'NE Lactation (MCal/Kg)', 'NE Maintenance (MCal/Kg)', 'NFC (%)', 'Neutral Detergent Fibre (%)', 'Phosphorus (%)', 'Potassium (%)', 'Sodium (%)', 'Starch (%)', 'Sulphur (%)', 'Total Digestible Nutrients (%)', 'Zinc (ug/g)', 'DIM_bins_w']\n",
    "    df = df.drop(columns = diet_columns)\n",
    "\n",
    "    # Assign Diet_ID\n",
    "    df = df.assign(\n",
    "        Diet_ID = lambda df: df['sampleId'] + '_' + df['reportDate'].dt.strftime('%Y-%m-%d')\n",
    "        )\n",
    "\n",
    "    # Calculate NDF intake by getting NDF (% DM) from database\n",
    "    conn = sqlite3.connect('../diet_database.db')\n",
    "    query = \"SELECT Diet_ID, `Neutral Detergent Fibre (%)` FROM current_diets\"\n",
    "    # create data frame from query:\n",
    "    df_NDF = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    # Merge dataframes\n",
    "    clean_data = pd.merge(\n",
    "        df,\n",
    "        df_NDF,\n",
    "        on = 'Diet_ID'\n",
    "    )\n",
    "    # Calculate NDF intake in kg\n",
    "    clean_data = clean_data.assign(\n",
    "    Dt_NDFIn = lambda df: df['Neutral Detergent Fibre (%)']/100 * df['Dt_DMIn']\n",
    "    )\n",
    "\n",
    "    # Drop unneeded columns\n",
    "    columns_to_drop = ['date', 'weight', 'asfed_intake', 'bcs_value', 'Birth Date', 'Test Day Date',\n",
    "                       'Lact Start Date', 'SCC', 'Pregnancy Indicator', 'Days to Last Breeding', \n",
    "                       'conception_date', 'age_m', 'sampleId', 'reportDate']\n",
    "    clean_data = clean_data.drop(columns = columns_to_drop)\n",
    "\n",
    "    return clean_data\n",
    "\n",
    "\n",
    "clean_data = clean_input_data(input_data_dropna)\n",
    "print(clean_data.iloc[:, :6].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ME_functions import *\n",
    "from MP_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Requirements for ME and MP\n",
    "\n",
    "clean_data['ME Requirement'] = clean_data.apply(lambda row: execute_ME_requirement(row), axis = 1)\n",
    "clean_data['MP Requirement'] = clean_data.apply(lambda row: execute_MP_requirement(row), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for cows missing data\n",
    "\n",
    "def check_na_requirement(df):    \n",
    "    columns_to_check = ['ME Requirement', 'MP Requirement']\n",
    "    check_na = df[columns_to_check].isna().any(axis=1)\n",
    "    cows_missing_data = df[check_na]\n",
    "    return cows_missing_data\n",
    "\n",
    "cows_missing_data = check_na_requirement(clean_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NASEM_py_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
